---
title: "MovieLens Recommendation System"
author: "Varun Tiwari"
date: "March 2020"
output: pdf_document
---

```{r, Global Settings, echo = FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
```

```{r, Load the Libraries}
library(tidyverse)
library(caret)
library(lubridate)
library(data.table)
library(ggplot2)
library(psych)
```


# Introduction

In this report, the **MovieLens 10M dataset** was used to create a **movie recommendation system algorithm** that can be used to predict how a certain user will rate a certain movie.

The **MovieLens 10M dataset** consists of 10,000,000 ratings of 10,000 movies by 72,000 users on a five-star scale. 

The data was pulled directly from the MovieLens website (https://grouplens.org/datasets/movielens/10m/).

The raw dataset was wrangled into a data frame, then split into the _edx_ training dataset and the _validation_ testing dataset.

The datasets were cleaned up, wrangled, and coerced into a more useable format.

The _edx_ dataset was explored and analyzed by plotting the data through the lenses of different potential effects.

An equation for the root mean squared error (RMSE) was defined as the target parameter.

Several models were trained using the _edx_ dataset and evaluated on the _validation_ dataset, including naive mean, effects, and regularization. The most effective models were then combined.

Using this method, a **movie recommendation system algorithm** with an **RMSE** of **0.863** was developed.


# Data Analysis and Model Development

## Create the Datasets

The raw datasets were pulled directly from the MovieLens website and saved to a temporary file. From the temporary file, the data was pulled in and coerced into two data frames, the _ratings_ data frame, with columns <u>userId</u>, <u>movieId</u>, <u>rating</u>, and <u>timestamp</u>, and the _movies_ data frame, with columns <u>movieId</u>, <u>title</u>, and <u>genres</u>. The two data frames were joined together by <u>movieId</u>, creating a new _movielens_ data frame with six columns, <u>userId</u>, <u>movieId</u>, <u>rating</u>, <u>timestamp</u>, <u>title</u>, and <u>genres</u>.

```{r, Pull Data from MovieLens Website}
dl <- tempfile()  # create temporary file location
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl) # download dataset to temporary file location
ratings <- str_split_fixed(readLines(unzip(dl,"ml-10M100K/ratings.dat")), "\\::", 4)  # parse downloaded data to create ratings dataset
colnames(ratings) <- c("userId", "movieId", "rating", "timestamp")  # name columns
ratings <- as.data.frame(ratings) %>% # coerce dataset into data frame and...
  mutate(userId = as.numeric(userId), # ...coerce userId column into numeric data type and...
         movieId = as.numeric(levels(movieId))[movieId], # ...coerce movieId column into numeric data type and...
         rating = as.numeric(levels(rating))[rating], # ...coerce rating column into numeric data type and...
         timestamp = as.numeric(levels(timestamp))[timestamp])  # ...coerce timestamp column into numeric data type 
movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3) # parse downloaded data to create movie dataset
colnames(movies) <- c("movieId", "title", "genres") # name columns
movies <- as.data.frame(movies) %>% # coerce dataset into data frame and...
  mutate(movieId = as.numeric(levels(movieId))[movieId], # ...coerce the movieId column into numeric data type and...
         title = as.character(title), # ...coerce title column into character data type and...
         genres = as.character(genres)) # ...coerce genre column into character data type
movielens <- left_join(ratings, movies, by = "movieId") # join ratings and movies data tables to create movielens dataset
rm(dl, movies, ratings) # remove unneeded variables in global environment
```

##### _movielens_ Dataset

```{r, Display MovieLens Dataset}
head(movielens)
```

The _movielens_ dataset was then split into two datasets, the _edx_ training dataset consisting of 90% of the data and the _temp_ dataset consisting of the remaining 10% of the data. Movies that only appear in the _temp_ dataset were removed, creating the _validation_ testing dataset. Those removed movies were then added to the _edx_ dataset.

```{r, Create edx (Train) and validation (Test) Datasets}
set.seed(1) # set seed to 1
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE) # create index with 10% of data for test set
edx <- movielens[-test_index,]  # create edx (train) dataset from test index
temp <- movielens[test_index,]  # create temporary (test) dataset from test index
validation <- temp %>%  # create final validation (test) dataset from temporary dataset...
  semi_join(edx, by = "movieId") %>%  # ...by identifying movies...
  semi_join(edx, by = "userId") # ...and users that only appear in temporary test set and not in edx train set
removed <- anti_join(temp, validation)  # identify movies and users that were removed from temporary test set
edx <- rbind(edx, removed)  # add movies and users removed from temporary test set to edx train set
rm(test_index, temp, movielens, removed)  # remove unneeded data from global environment
```

##### _edx_ Dataset

```{r, Display edx Dataset}
head(edx) # display first six lines of data
```

##### _validation_ Dataset

```{r, Display validation Dataset}
head(validation)  # display first six lines of data
```

## Clean the Datasets

Looking at the _edx_ dataset again, there is some data cleaning that can be done to make the data easier to visualize and analyze.

##### _edx_ Dataset

```{r, Display edx Dataset Again}
head(edx) # display first six lines of data
```

The <u>timestamp</u> column is the time the review was submitted, formatted as the number of seconds since January 1, 1970. It can be converted to a date_time data type.

The movie release year is included in <u>title</u> column. It can be extracted, added as the new column <u>year</u>, and converted to a numeric data type.

The columns <u>timestamp</u> and <u>year</u> can be used to calculate the number of years between the movie's release year and the year the movie was reviewed and create a new column <u>yearsbetween</u>.

Some movies fall into more than one genre in the <u>genres</u> column. Reviews of movies with more than one genre can be separated out by genre into multiple duplicate reviews with one genre per review.

##### Cleaned _edx_ Dataset

```{r, edx Data Cleaning}
edx <- edx %>%  # take data and...
  mutate(timestamp = as_datetime(timestamp)) %>%  # ...coerce timestamp into date_time data type for better analysis and...
  mutate(year = substring(title, nchar(title) - 6)) %>% # ...pull year released from movie title and add it as new column and...
  mutate(year = as.numeric(substring(year, regexpr("\\(", year) + 1, regexpr("\\)", year) - 1))) %>%  # ...remove parenthesis and set as numeric and...
  mutate(yearsbetween = as.numeric(year(timestamp)) - year) %>%  # ...calculate time between movie's release and review and...
  separate_rows(genres, sep = "\\|")  # ...separate out rows with multiple genres into multiple duplicate rows
head(edx, 19) # display first 19 lines of data, which is the first 6 ratings with one line per genre
```

The same steps were carried out on the _validation_ dataset.

```{r, validation Data Cleaning}
validation <- validation %>%  # take data and...
  mutate(timestamp = as_datetime(timestamp)) %>%   # ...coerce timestamp into date_time data type for better analysis
  mutate(year = substring(title, nchar(title) - 6)) %>% # ...pull year released from movie title and add it as a new column and...
  mutate(year = as.numeric(substring(year, regexpr("\\(", year) + 1, regexpr("\\)", year) - 1))) %>%  # ...remove parenthesis and set as numeric and...
  mutate(yearsbetween = as.numeric(year(timestamp)) - year) %>%  # ...calculate the time between release and review and...
  separate_rows(genres, sep = "\\|")  # ...separate out rows with multiple genres into multiple duplicate rows
```

## Cursory Data Visualizations and Analysis

All visualizations and analyses were performed with the _edx_ training dataset.

The average rating is 3.53 stars. The 4 stars is the median rating.

```{r, Average and Median}
avg_rating <- mean(edx$rating)  # calculate average rating
med_rating <- median(edx$rating)  # calculate median rating
```

Grouping the data by rating shows that four stars is most common rating and that full star ratings are given more often than half star ratings.

##### Ratings

```{r, Group by Rating}
edx_ratings <- edx %>%  # take data and...
  group_by(rating) %>%  # ...group data by rating and...
  summarize(num_ratings = n()) %>% # ...summarize frequency of each rating and...
  arrange(desc(num_ratings)) # ...arrange data in descending order
edx_ratings # display rating frequencies
edx_ratings %>% # for each rating, plot frequency
  ggplot(aes(rating, num_ratings, color = rating)) +
  geom_point(aes(size = num_ratings)) +
  scale_color_gradientn(colours = rainbow(5)) +
  scale_size_continuous(limits = c(0, 7e+06)) +
  xlim(0,5) +
  labs(x = "Rating", y = "Number of Ratings", title = "Ratings by Rating", color = "Rating", size = "Number of Ratings")
```

Grouping the data by movie shows that in general, movies that are reviewed often have higher average ratings and that there is more variation in average ratings for movies that have few reviews.

##### Movies

```{r, Group by Movie}
edx_movies <- edx %>% # take data and...
  group_by(movieId) %>% # ...group by movie and...
  summarize(num_ratings = n(), avg_rating = mean(rating)) %>% # ...summarize ratings counts and average rating and...
  arrange(desc(num_ratings)) # ...arrange data in descending order
headTail(edx_movies)  # display top and bottom movies by number of ratings
edx_movies %>% # for each movie, plot the number of ratings v num of ratings
  ggplot(aes(movieId, num_ratings, color = avg_rating)) +
  geom_point() +
  scale_color_gradientn(colours = rainbow(5)) +
  labs(x = "MovieId", y = "Number of Ratings", title = "Ratings by Movie", color = "Average Rating")
```

Grouping the data by user shows that most users give an average rating near the overall average and that there is more variation in average ratings for users that have only given a few ratings, when compared to users that have rated many movies.

##### Users

```{r, Group by User}
edx_users <- edx %>% # take data and...
  group_by(userId) %>% # ...group by user and...
  summarize(num_ratings = n(), avg_rating = mean(rating)) %>% # ...summarize ratings counts and average rating and...
  arrange(desc(num_ratings)) # ...arrange data in descending order
headTail(edx_users) # display top and bottom users by number of ratings
edx_users %>% # for each movie, plot the number of ratings v num of ratings
  ggplot(aes(userId, num_ratings, color = avg_rating)) +
  geom_point() +
  scale_color_gradientn(colours = rainbow(5)) +
  labs(x = "UserId", y = "Number of Ratings", title = "Ratings by User", color = "Average Rating")
```

Grouping the data by genre shows that the most common genres are Drama, Comedy, and Action and that the best rated genres, like Film-Noir, War, and Documentary have fewer movies and ratings.

##### Genres

```{r, Group by Genre}
edx_genres <- edx %>% # take data and...
  group_by(genres) %>% # ...group data by genre and...
  summarize(num_ratings = n(), avg_rating = mean(rating)) %>% # ...summarize ratings counts and average rating and...
  arrange(desc(num_ratings)) # ...arrange data in descending order
edx_genres # display genre data
edx_genres %>% # for each genre, plot the number of ratings and average rating
  ggplot(aes(genres, avg_rating)) +
  geom_point(aes(size = num_ratings)) +
  scale_size_continuous(limits = c(0, 7e+06)) +
  labs(x = "Genre", y = "Average Rating", title = "Ratings by Genre", size = "Number of Ratings") +
  theme(axis.text.x = element_text(angle = 90))
```

Grouping the data by movie release year shows that pre-1980 years are better rated than post-1980 years and that movies released in recent years have received more ratings.

##### Release Year

```{r, Group by Year}
edx_years <- edx %>% # take data and...
  group_by(year) %>% # ...group data by years between movie release and rating and...
  summarize(num_ratings = n(), avg_rating = mean(rating)) %>% # ...summarize ratings counts and average rating and...
  arrange(desc(num_ratings)) # ...arrange data in descending order
headTail(edx_years) # display year data
edx_years %>% # for each year, plot the number of ratings and average rating
  ggplot(aes(year, avg_rating, size = num_ratings)) +
  geom_point(aes(size = num_ratings)) +
  scale_size_continuous(limits = c(0, 7e+06)) +
  labs(x = "Year", y = "Average Rating", title = "Ratings by Year", size = "Number of Ratings")
```

Grouping the data by the number of years between release and review shows that movies that are reviewed before they have been released tend to be reviewed quite poorly and that generally, the more time between a movie's release and the time it was reviewed, the higher the rating tends to be.

##### Years between Release and Review

```{r, Group by Years between}
edx_yearsbetween <- edx %>% # take data and...
  group_by(yearsbetween) %>% # ...group data by number of years between release and rating and...
  summarize(num_ratings = n(), avg_rating = mean(rating)) %>% # ...summarize ratings counts and average rating and...
  arrange(desc(num_ratings)) # ...arrange data in descending order
headTail(edx_yearsbetween) # display year data
edx_yearsbetween %>% # for each number of years between release and review, plot the number of ratings and average rating
  ggplot(aes(yearsbetween, avg_rating, size = num_ratings)) +
  geom_point(aes(size = num_ratings)) +
  scale_size_continuous(limits = c(0, 7e+06)) +
  labs(x = "Years between Movie Release and Rating", y = "Average Rating", title = "Ratings by Years between Release and Rating", size = "Number of Ratings")
```

## Defining RMSE

The goal of this project is to develop an algorithm with the lowest possible residual mean squared error (RMSE). RMSE is defined as the error that the algorithm makes when predicting a rating, or:

$$\sqrt{\frac{1}{N} \sum_{e} (\hat{y}_{e} - y_{e})^2}$$

where $N$ is the total number of user/movie ratings, $\hat{y}_{e}$ is the predicted rating for a particular review given effects $e$, and $y_{e}$ is the actual rating for a particular review given effects $e$.

```{r, Define Function to Calculate RMSE}
rmse <- function(true_ratings, predicted_ratings){  # define function that takes true ratings and predicted ratings and...
  sqrt(mean((true_ratings - predicted_ratings)^2))  # ...calculates residual mean squared error
}
```

An RMSE of 1 would mean that on average, the rating that the algorithm predicted is one star off the actual rating.

## Modeling Approach

### A Simple Model - Average

The simplest model predicts the same rating for each review, regardless of effects like movie, user, genre, etc. This model can be defined as:

$$Y = \mu + \epsilon$$
where $Y$ is the outcome (predicted rating), $\mu$ is the average rating, and $\epsilon$ is the error.

```{r, Model 1 - Average}
average <- mean(edx$rating)  # calculate the average rating
rmse_average <- rmse(validation$rating, average) # calculate rmse for model
model_rmses <- tibble(model = "Average", rmse = rmse_average) # create a table to display all the calculated rmses
```

The **RMSE** of the **Average** model is **1.053**.

### Introducing Effects

Introducing effects allows the model to take variability into account. Looking at the visualizations above, for example, some movies are, on average, rated higher than others and certain genres tend to receive lower average ratings than others. The effects model can be defined as:

$$Y = \mu + e_a + \epsilon$$

where $e_a$ is the effect term of effect $a$.

For modeling purposes, the least square estimate of $e_a$ is the average of $Y_a - \mu$ for each instance of effect $a$.

Based on the above visualizations, movie, user, genre, year released, and years between release and review effects were all introduced to the model.

### Movie Effect

The **Average + Movie Effect** model is defined as

$$Y = \mu + e_m + \epsilon$$

where $e_m$ is the effect term for movie $m$.

```{r, Model 2 - Movie Effect}
movie_effect <- edx %>% # take data and...
  group_by(movieId) %>% # ...group it by movie and...
  summarize(e_m = mean(rating - average)) # calculate e_m for each movie by taking average of difference between each rating and average rating

movie_pred_ratings <- validation %>% # take testing dataset and...
  left_join(movie_effect, by ="movieId") %>% # ...join it to training data set by movie and...
  mutate(predicted_rating = average + e_m) %>% # ...calculate predicted ratings and...
  pull(predicted_rating)  # ...pull predicted ratings

rmse_movie_effect <- rmse(validation$rating, movie_pred_ratings)  # calculate rmse for model
model_rmses <- bind_rows(model_rmses,
                         tibble(model = "Average + Movie Effect", rmse = rmse_movie_effect)) # add calculated rmse to rmse table
```

The **RMSE** of the **Average + Movie Effect** model is **0.941**.

### User Effect

The **Average + User Effect** model is defined as

$$Y = \mu + e_u + \epsilon$$
where $e_u$ is the effect term for user $u$.

```{r, Model 3 - User Effect}
user_effect <- edx %>% # take data and...
  group_by(userId) %>%  # ...group by user and...
  summarize(e_u = mean(rating - average)) # ...calculate e_u for each user by taking average of difference between each rating and average rating

user_pred_ratings <- validation %>% # take test dataset and...
  left_join(user_effect, by = "userId") %>% # ...join it to training dataset by user and...
  mutate(predicted_rating = average + e_u) %>% #...calculate predicted ratings and...
  pull(predicted_rating)  # ...pull predicted ratings

rmse_user_effect <- rmse(validation$rating, user_pred_ratings)  # calculate rmse for model
model_rmses <- bind_rows(model_rmses,
                         tibble(model = "Average + User Effect", rmse = rmse_user_effect)) # add calculated rmse to rmse table
```

The **RMSE** of the **Average + User Effect** model is **0.973**.

### Genre Effect

The **Average + Genre Effect** model is defined as

$$Y = \mu + e_g + \epsilon$$
where $e_g$ is the effect term for genre $g$.

```{r, Model 4 - Genre Effect}
genre_effect <- edx %>% # take data and...
  group_by(genres) %>% # ...group by genre and...
  summarize(e_g = mean(rating - average)) # calculate e_g for each genre by taking average of difference between each rating and average rating

genre_pred_ratings <- validation %>% # take test dataset and...
  left_join(genre_effect, by = "genres") %>%  # ...join it to training dataset by genre and...
  mutate(predicted_rating = average + e_g) %>% # ...calculate predicted ratings and...
  pull(predicted_rating)  # pull predicted ratings

rmse_genre_effect <- rmse(validation$rating, genre_pred_ratings)  # calculate rmse for model
model_rmses <- bind_rows(model_rmses,
                         tibble(model = "Average + Genre Effect", rmse = rmse_genre_effect)) # add calculated rmse to rmse table
```

The **RMSE** of the **Average + Genre Effect** model is **1.046**.

### Year Effect

The **Average + Year Effect** model is defined as

$$Y = \mu + e_y + \epsilon$$
where $e_y$ is the effect term for release year $y$.

```{r, Model 5 - Year Effect}
year_effect <- edx %>% # take data and...
  group_by(year) %>% # ...group by year released and...
  summarize(e_y = mean(rating - average)) # calculate e_y for each year by taking average of difference between each rating and average rating

year_pred_ratings <- validation %>% # take test dataset and...
  left_join(year_effect, by = "year") %>% # join it to training dataset by time between release and ratings and...
  mutate(predicted_rating = average + e_y) %>% # ...calculate predicted ratings and...
  pull(predicted_rating)  # ...pull predicted ratings

rmse_year_effect <- rmse(validation$rating, year_pred_ratings)  # calculate rmse for model
model_rmses <- bind_rows(model_rmses,
                         tibble(model = "Average + Year Effect", rmse = rmse_year_effect)) # add calculated rmse to rmse table
```

The **RMSE** of the **Average + Year Effect** model is **1.042**.

### Years between Effect

The **Average + Years between Effect** model is defined as

$$Y = \mu + e_yb + \epsilon$$
where $e_yb$ is the effect term for years between the movie's release and review $yb$.

```{r, Model 6 - Years between Effect}
yearsbetween_effect <- edx %>% # take data and...
  group_by(yearsbetween) %>% # ...group by time between release and ratings and...
  summarize(e_yb = mean(rating - average)) # calculate e_y for each time frame by taking average of difference between each rating and average rating

yearsbetween_pred_ratings <- validation %>% # take test dataset and...
  left_join(yearsbetween_effect, by = "yearsbetween") %>% # join it to training dataset by time between release and ratings and...
  mutate(predicted_rating = average + e_yb) %>% # ...calculate predicted ratings and...
  pull(predicted_rating)  # ...pull predicted ratings

rmse_yearsbetween_effect <- rmse(validation$rating, yearsbetween_pred_ratings)  # calculate rmse for model
model_rmses <- bind_rows(model_rmses,
                         tibble(model = "Average + Years between Effect", rmse = rmse_yearsbetween_effect)) # add calculated rmse to rmse table
```

The **RMSE** of the **Average + Years between Effect** model is **1.045**.

### Introducing Regularization

Looking at the visualizations above again, there is a lot of variation in the number of ratings that different movies receive, different users give, etc. Regularization will introduce a penalized term that will have a great effect on large predicted ratings stemming from small group sizes while having little effect on predicted ratings stemming from large group sizes.

$$e_a = \frac{\sum_{1}^{n_a}(Y_a - \mu)}{n_a + \lambda_a}$$
where $n_a$ is the number of ratings for effect $a$, $Y_a$ is the average rating for effect $a$, and $\lambda_a$ is the penalization term for effect $a$.

### Movie Regularization 

The **Average + Movie Effect + Regularization** model is defined as

$$Y = \mu + e_m + \epsilon$$
where

$$e_m = \frac{\sum_{1}^{n_m}(Y_m - \mu)}{n_m + \lambda_m}$$
```{r, Model 7 - Movie Regularization}
lambdas <- seq(0, 10, 0.25) # define a set of lambdas to test

reg_movie_rmses <- sapply(lambdas, function(l){ # calculate rmses for all defined lambdas by creating a function that...
  e_m <- edx %>% # ...takes data and...
    group_by(movieId) %>% # ...groups it by movie and...
    summarize(e_m = sum(rating - average) / (n() + l))  # calculates e_m then...
  predicted_ratings <- validation %>% # ...takes test dataset and...
    left_join(e_m, by = "movieId") %>% # ...joins it to train dataset by movie and...
    mutate(pred = average + e_m) %>% # ...calculates a predicted rating and...
    pull(pred)  # ...pulls predicted ratings and...
  return(rmse(validation$rating, predicted_ratings))  # ...returns rmses for each lambda
})

rmse_reg_movie_effect <- min(reg_movie_rmses) # return minimum rmse
model_rmses <- bind_rows(model_rmses,
                         tibble(model = "Average + Movie Effect + Regularization", rmse = rmse_reg_movie_effect)) # add calculated rmse to rmse table

```

The **RMSE** of the **Average + Movie Effect + Regularization** model is **0.941**, which is no improvement over the non-regularized model.


# Results - The Best Model

Looking that the models described above, only two of them, **Movie Effect** and **User Effect** made significant improvements to the **Average** model.

```{r, display model_rmses}
model_rmses  # display calculated RMSES
```

By combining these two effects, the model should become more accurate.

The **Average + Movie + User Effects** model is defined as

$$Y = \mu + e_m + e_u + \epsilon$$

```{r, Model 8 - Combine the Best Effects}
movie_effect <- edx %>% # take data and...
  group_by(movieId) %>% # ...group it by movie and...
  summarize(e_m = mean(rating - average)) # calculate e_m for each movie by taking average of difference between each rating and average rating

movie_user_effect <- edx %>% # take data and...
  left_join(movie_effect, by = "movieId") %>% # join it to movie_effect dataset by movie and...
  group_by(userId) %>% # ...group by user and...
  summarize(e_u = mean(rating - average - e_m)) # ... calculate e_u for each user by taking average of difference between each rating and average rating and calculated e_m

movie_user_pred_ratings <- validation %>% # take test dataset and...
  left_join(movie_effect, by = "movieId") %>%  # join it to movie_effect dataset by movie and...
  left_join(movie_user_effect, by = "userId") %>% # join it to movie_effect dataset by movie and...
  mutate(predicted_rating = average + e_m + e_u) %>% # ...calculate predicted ratings and...
  pull(predicted_rating)  # ...pull predicted ratings

best_model_rmse <- rmse(validation$rating, movie_user_pred_ratings)  # calculate rmse for model
model_rmses <- bind_rows(model_rmses,
                         tibble(model = "Average + Movie + User Effects", rmse = best_model_rmse)) # add calculated rmse to rmse table
```

##### Best Effects Model

```{r, display best model_rmse}
model_rmses[8,]
```


The **RMSE** of the **Average + Movie + User Effect** model is **0.863**.


# Conclusions

After visually analyzing and examining the data and testing several models, an algorithm to predict movie ratings with an **RMSE** of **0.863** was developed by defining a model that included effects.

$$Y = \mu + e_m + e_u + \epsilon$$